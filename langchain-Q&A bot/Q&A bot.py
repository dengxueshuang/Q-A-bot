import os
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import SentenceTransformerEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_community.llms import Ollama

# åŠ è½½æ‰€æœ‰ markdown æ–‡ä»¶
def load_markdown_documents(folder_path):
    docs = []
    for filename in os.listdir(folder_path):
        if filename.endswith(".md"):
            loader = TextLoader(os.path.join(folder_path, filename), encoding='utf-8')
            docs.extend(loader.load())
    print(f"ğŸ“„ åŠ è½½å®Œæˆï¼š{len(docs)} ä¸ª Markdown æ–‡æ¡£")
    return docs

# åˆ‡åˆ†æ–‡æ¡£
def split_documents(documents):
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    return splitter.split_documents(documents)

# æ„å»ºå‘é‡æ•°æ®åº“
def build_vector_store(docs):
    embeddings = SentenceTransformerEmbeddings(model_name="all-MiniLM-L6-v2")
    return FAISS.from_documents(docs, embeddings)

# æ„å»ºé—®ç­”é“¾
def build_qa_chain(vector_store):
    llm = Ollama(model="deepseek-r1:1.5b")
    return RetrievalQA.from_chain_type(llm=llm, retriever=vector_store.as_retriever())

def main():
    # æ­¥éª¤ 1ï¼šåŠ è½½å¹¶åˆ‡åˆ† Markdown æ–‡æ¡£
    docs = load_markdown_documents("docs")
    chunks = split_documents(docs)

    # æ­¥éª¤ 2ï¼šæ„å»ºå‘é‡åº“
    vector_store = build_vector_store(chunks)

    # æ­¥éª¤ 3ï¼šæ„å»º QA é—®ç­”é“¾
    qa = build_qa_chain(vector_store)

    # æ­¥éª¤ 4ï¼šé—®ç­”äº¤äº’
    while True:
        query = input("\nâ“è¯·è¾“å…¥é—®é¢˜ï¼ˆexit é€€å‡ºï¼‰ï¼š")
        if query.lower() in ['exit', 'quit']:
            break
        result = qa.run(query)
        print(f"âœ… ç­”æ¡ˆï¼š{result}")

if __name__ == "__main__":
    main()
